{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 import required modules\n",
    "import time\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import neighbors\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn.datasets import get_data_home\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from urllib.request import urlopen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.  read the NMIST dataset\n",
    "memory = Memory(get_data_home())\n",
    "@memory.cache()\n",
    "def fetch_mnist():\n",
    "    content = urlopen(\n",
    "        'https://www.openml.org/data/download/52667/mnist_784.arff').read()\n",
    "    data, meta = loadarff(io.StringIO(content.decode('utf8')))\n",
    "    data = data.view([('pixels', '<f8', 784), ('class', '|S1')])\n",
    "    return data['pixels'], data['class']\n",
    "X, y = fetch_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "\n",
    "X = X / 255.\n",
    "\n",
    "###### NEW  Refromat the the labels to be integers rather than byte arrays\n",
    "y_trans = []\n",
    "for i in range(len(y)):\n",
    "    y_trans.append(int(y[i]))\n",
    "y = np.asarray(y_trans)\n",
    "\n",
    "X_train, X_test = X[:2000], X[2000:2200]\n",
    "y_train, y_test = y[:2000], y[2000:2200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_trans = []\n",
    "for i in range(len(y)):\n",
    "    y_trans.append(int(y[i]))\n",
    "y = np.asarray(y_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN neighbor = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0.131 seconds\n",
      "Test score with 3NN is: 0.9150\n",
      "Test time 0.990 seconds\n",
      "Test score with 3NN is: 0.9150\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 3NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 3NN is: %.4f\" % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN neighbor=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0.140 seconds\n",
      "Test score with 5NN is: 0.9200\n",
      "Test time 0.957 seconds\n",
      "Test score with 5NN is: 0.9200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 5NN is: %.4f\" % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN neighbor=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 0.161 seconds\n",
      "Test score with 1NN is: 0.9300\n",
      "Test time 0.952 seconds\n",
      "Test score with 1NN is: 0.9300\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "#Train the classifier\n",
    "KNN.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = KNN.score(X_test,y_test)\n",
    "print(\"Test score with 1NN is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time %.3f seconds\" % test_time)\n",
    "print(\"Test score with 1NN is: %.4f\" % score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single hidden layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard scientific Python import\n",
    "import time\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import get_data_home\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import check_random_state\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rescale the data, use the traditional train/test split\n",
    "\n",
    "X = X / 255.\n",
    "\n",
    "###### NEW  Refromat the the labels to be integers rather than byte arrays\n",
    "y_trans = []\n",
    "for i in range(len(y)):\n",
    "    y_trans.append(int(y[i]))\n",
    "y = np.asarray(y_trans)\n",
    "\n",
    "X_train, X_test = X[:10000], X[10000:10200]\n",
    "y_train, y_test = y[:10000], y[10000:10200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30454215\n",
      "Iteration 2, loss = 2.30125955\n",
      "Iteration 3, loss = 2.30120262\n",
      "Iteration 4, loss = 2.30058722\n",
      "Iteration 5, loss = 2.30042938\n",
      "Iteration 6, loss = 2.29943975\n",
      "Iteration 7, loss = 2.29867319\n",
      "Iteration 8, loss = 2.29834305\n",
      "Iteration 9, loss = 2.29773144\n",
      "Iteration 10, loss = 2.29659269\n",
      "Iteration 11, loss = 2.29551009\n",
      "Iteration 12, loss = 2.29415868\n",
      "Iteration 13, loss = 2.29271219\n",
      "Iteration 14, loss = 2.29080467\n",
      "Iteration 15, loss = 2.28815967\n",
      "Iteration 16, loss = 2.28567883\n",
      "Iteration 17, loss = 2.28233864\n",
      "Iteration 18, loss = 2.27804437\n",
      "Iteration 19, loss = 2.27350144\n",
      "Iteration 20, loss = 2.26689236\n",
      "Iteration 21, loss = 2.25943889\n",
      "Iteration 22, loss = 2.25020769\n",
      "Iteration 23, loss = 2.23991498\n",
      "Iteration 24, loss = 2.22809553\n",
      "Iteration 25, loss = 2.21294113\n",
      "Iteration 26, loss = 2.19509497\n",
      "Iteration 27, loss = 2.17492325\n",
      "Iteration 28, loss = 2.15165413\n",
      "Iteration 29, loss = 2.12602172\n",
      "Iteration 30, loss = 2.09749275\n",
      "Iteration 31, loss = 2.06691795\n",
      "Iteration 32, loss = 2.03546323\n",
      "Iteration 33, loss = 1.99887825\n",
      "Iteration 34, loss = 1.97120796\n",
      "Iteration 35, loss = 1.93659810\n",
      "Iteration 36, loss = 1.89858619\n",
      "Iteration 37, loss = 1.92144571\n",
      "Iteration 38, loss = 1.83605941\n",
      "Iteration 39, loss = 1.87642970\n",
      "Iteration 40, loss = 1.79389169\n",
      "Training time of Single hidden layer perceptron is: 17.264 seconds\n",
      "Test score with Single hidden layer perceptron is: 0.5300\n",
      "Test time of of Single hidden layer perceptron is: 0.019 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (40) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "# Single hidden layer\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=40, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "# Note, the iteration limit will be reached! \n",
    "#Train the classifier\n",
    "mlp.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time of Single hidden layer perceptron is: %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp.score(X_test,y_test)\n",
    "print(\"Test score with Single hidden layer perceptron is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time of of Single hidden layer perceptron is: %.3f seconds\" % test_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double hidden layer perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30800662\n",
      "Iteration 2, loss = 2.30288661\n",
      "Iteration 3, loss = 2.30179307\n",
      "Iteration 4, loss = 2.30179997\n",
      "Iteration 5, loss = 2.30213552\n",
      "Iteration 6, loss = 2.30119653\n",
      "Iteration 7, loss = 2.30092266\n",
      "Iteration 8, loss = 2.30070933\n",
      "Iteration 9, loss = 2.29981106\n",
      "Iteration 10, loss = 2.30022172\n",
      "Iteration 11, loss = 2.29862128\n",
      "Iteration 12, loss = 2.29712283\n",
      "Iteration 13, loss = 2.29611147\n",
      "Iteration 14, loss = 2.29387955\n",
      "Iteration 15, loss = 2.28984783\n",
      "Iteration 16, loss = 2.28109478\n",
      "Iteration 17, loss = 2.26712063\n",
      "Iteration 18, loss = 2.24307923\n",
      "Iteration 19, loss = 2.25598550\n",
      "Iteration 20, loss = 2.27592082\n",
      "Iteration 21, loss = 2.22471399\n",
      "Iteration 22, loss = 2.25716824\n",
      "Iteration 23, loss = 2.21686140\n",
      "Iteration 24, loss = 2.27704808\n",
      "Iteration 25, loss = 2.25683880\n",
      "Iteration 26, loss = 2.21989608\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training time of Double hidden layer perceptron is: 10.984 seconds\n",
      "Test score with Double hidden layer perceptron is: 0.2000\n",
      "Test time of of Double hidden layer perceptron is: 0.039 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "# Two hidden layers\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(50,50), max_iter=40, alpha=1e-4,\n",
    "                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n",
    "                    learning_rate_init=.1)\n",
    "#\n",
    "#Train the classifier\n",
    "mlp_2.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time of Double hidden layer perceptron is: %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = mlp_2.score(X_test,y_test)\n",
    "print(\"Test score with Double hidden layer perceptron is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time of of Double hidden layer perceptron is: %.3f seconds\" % test_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear function SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time of linear function SVM is: 1.704 seconds\n",
      "Test score with linear function SVM is: 0.9200\n",
      "Test time of of linear function SVM is: 0.198 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "## Linear\n",
    "clf = svm.SVC(kernel = 'linear', C = 1)\n",
    "##\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time of linear function SVM is: %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with linear function SVM is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time of of linear function SVM is: %.3f seconds\" % test_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynormial function SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time of polynormial function SVM is: 7.816 seconds\n",
      "Test score with polynormila function SVM is: 0.1100\n",
      "Test time of polynormial function SVM is: 0.528 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "## Linear\n",
    "clf = svm.SVC(kernel = 'poly',degree = 3, C = 1)\n",
    "##\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time of polynormial function SVM is: %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with polynormila function SVM is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time of polynormial function SVM is: %.3f seconds\" % test_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# radial basis function SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time of radial basis function SVM is: 8.571 seconds\n",
      "Test score with radial basis function SVM is: 0.1850\n",
      "Test time of ofradial basis function SVM is: 0.577 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "#Classifier Declaration\n",
    "## Radial basis functions\n",
    "clf = svm.SVC(kernel = 'rbf', C = 1, gamma = 0.5)\n",
    "\n",
    "#Train the classifier\n",
    "clf.fit(X_train,y_train)\n",
    "train_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print(\"Training time of radial basis function SVM is: %.3f seconds\" % train_time)\n",
    "#Evaluate the result\n",
    "score = clf.score(X_test,y_test)\n",
    "print(\"Test score with radial basis function SVM is: %.4f\" % score)\n",
    "test_time = time.time() - start_time\n",
    "print(\"Test time of ofradial basis function SVM is: %.3f seconds\" % test_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Discuss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the trainning and test time.\n",
    "my trainning set is the first 2000 iamges.\n",
    "my test set is the 2000-2200 images.\n",
    "Previously I tried to use the first 10000 images to train and the last 10000 images to test, but due to the performance of my virtual machine, the trainning time is so long, more than 40 minuets, so I gave up and choosed the 200 images smaller set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neighbors = 1:\n",
    "Training time is 0.161 seconds\n",
    "Test score is: 0.9300\n",
    "Test time 0.952 seconds\n",
    "\n",
    "For neighbors = 3: \n",
    "Training time is 0.131 seconds\n",
    "Test score is: 0.9150\n",
    "Test time is 0.990 seconds\n",
    "\n",
    "For neighbors = 5:\n",
    "Training time is 0.140 seconds\n",
    "Test score is: 0.9200\n",
    "Test time is 0.957 seconds\n",
    "\n",
    "As the increase of neighbors, the score is almost the same, they are not in linear relationship. From the result, I guess K should be smaller so that the trainning quality will be better.\n",
    "In k-NN classification, the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors. And k is a small positive integer. If k = 1, then the object is simply assigned to the class of that single nearest neighbor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the tranning and test is a lot more faster for hidden layer perceptron compared with KNN and SVM, so to speed up the trainning and test time. my trainning set is the first 10000 iamges. my test set is the 10000-10200 images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For single hidden layer perceptron: I set the hidden_layer_sizes=(50,50), max_iter=40, alpha=1e-4, in every iteration, the loss fluctuate a lot, in a large range, the loss decreases from 2.3 to 1.8. Finally the loss is around 1.8.\n",
    "Although after 40 itertions, my model still does not convergent, but the score is already very high:\n",
    "Training time of Single hidden layer perceptron is: 17.264 seconds\n",
    "Test score with Single hidden layer perceptron is: 0.5300\n",
    "Test time of of Single hidden layer perceptron is: 0.019 seconds\n",
    "\n",
    "For double hidden layer perceptron: I set the hidden_layer_sizes=(50,50), max_iter=40, alpha=1e-4, in every iteration, the loss fluctuate a lot, in a large range, the loss decreases from 2.3 to 2.21. Finally the loss is around 2.21.\n",
    "40 iterations is so many, when loss did not improve more than tol=0.000100 for two consecutive epochs, I set it as convergent and let my program stop. So my model convergent at the 26 iterations, the score is pretty high, results are pretty good as below:\n",
    "Training time of Double hidden layer perceptron is: 10.984 seconds\n",
    "Test score with Double hidden layer perceptron is: 0.2000\n",
    "Test time of of Double hidden layer perceptron is: 0.039 seconds\n",
    "\n",
    "The classify result of single layer perceptron is better than double layer perceptron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the trainning and test time. My trainning set is the first 2000 iamges. my test set is the 2000-2200 images. Previously I tried to use the first 10000 images to train and the last 10000 images to test, but it only works for linear function SVM,for linear function SVM, the result is :\n",
    "\n",
    "Training time of linear function SVM is: 17.567 seconds\n",
    "Test score with linear function SVM is: 0.9100\n",
    "Test time of of linear function SVM is: 0.659 seconds\n",
    "\n",
    "But due to the performance of my virtual machine, for polynormial and radix basis function SVM, the trainning time is so long, more than 40 minuets, so I gave up and choosed the 200 images smaller set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training time of linear function SVM is: 1.704 seconds\n",
    "Test score with linear function SVM is: 0.9200\n",
    "Test time of of linear function SVM is: 0.198 seconds\n",
    "\n",
    "Training time of polynormial function SVM is: 7.816 seconds\n",
    "Test score with polynormila function SVM is: 0.1100\n",
    "Test time of polynormial function SVM is: 0.528 seconds\n",
    "\n",
    "Training time of radial basis function SVM is: 8.571 seconds\n",
    "Test score with radial basis function SVM is: 0.1850\n",
    "Test time of ofradial basis function SVM is: 0.577 seconds\n",
    "\n",
    "the classify result for linear function SVM is the best, and the polynormial function SVM is the worst.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, the best classification result is KNN, and then hidden layer perceptron, the least is SVM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
