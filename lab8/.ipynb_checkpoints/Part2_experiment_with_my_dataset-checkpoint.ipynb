{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HFaJAIhfMCVv"
   },
   "source": [
    "# Part 2 Experiment with my dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wRZk9J60MI2U"
   },
   "source": [
    "\n",
    "## Prepare the model and load my dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zhx0lFViFm2k"
   },
   "outputs": [],
   "source": [
    "#install torch in google colab\n",
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "nfiM3AQXFqkO",
    "outputId": "55f4c7ff-053e-4e78-d840-a4831e8f11dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "hgAEBppGFtub",
    "outputId": "900053d1-9417-4337-d3c6-9b46a97c8f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data\n",
      "    Transforms (if any): None\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "#initialization\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "len(mnist_trainset)\n",
    "print(mnist_trainset)\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "FgbhYfoqF2GN",
    "outputId": "aded9aac-4628-4649-b9e1-92e03a06aadb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "# Mounte files to gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "wH3CZkCfF4zm"
   },
   "outputs": [],
   "source": [
    "# loade test myDateSet\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, data_path, csv_name, transform = None ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path (string): path to the folder where images and csv files are located\n",
    "            csv_name (string): name of the csv lablel file\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        # Set path\n",
    "        self.data_path = data_path\n",
    "        # Transforms\n",
    "        self.transform = transform\n",
    "        # Read the csv file\n",
    "        self.data_info = pd.read_csv(data_path + csv_name, header=None)\n",
    "        # First column contains the image paths\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        # Second column is the labels\n",
    "        self.label_arr = np.asarray(self.data_info.iloc[:, 1])\n",
    "        # Calculate len\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Get image name from the pandas df\n",
    "        single_image_name = self.image_arr[index]\n",
    "        # Open image\n",
    "        img_as_img = Image.open(self.data_path + single_image_name)\n",
    "        if self.transform is not None:\n",
    "              img_as_img = self.transform(img_as_img)\n",
    "\n",
    "        # Get label(class) of the image based on the cropped pandas column\n",
    "        single_image_label = self.label_arr[index]\n",
    "        #convert to tensor to be consistent with MNIST dataset\n",
    "        single_image_label = torch.LongTensor( [ single_image_label ] )[0]\n",
    "        return (img_as_img, single_image_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "\n",
    "#mydata = SimpleDataset( \"gdrive/My Drive/myDataSet/\", \"label.csv\")\n",
    "mydataT = SimpleDataset( \"gdrive/My Drive/myDataSet/\", \"label.csv\", transform=transforms.ToTensor())\n",
    "\n",
    "#testc = mydataT[1]\n",
    "#testT = testc[0]\n",
    "#imgt = Image.fromarray((testT.numpy()[0] * 255).astype(\"uint8\"))\n",
    "#display(imgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XZxxezOlF_A0"
   },
   "outputs": [],
   "source": [
    "# loade My test set to make my test loader\n",
    "my_test_loader = torch.utils.data.DataLoader(dataset=mydataT,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vIrLyMYNGCGp"
   },
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kcebFOUWGE7P"
   },
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uw8xrsotJe4G"
   },
   "source": [
    "## 1.1 experiment on 100 size trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "ZhA9XSDGG9ag",
    "outputId": "73686e26-ea8f-4cdd-f284-d1b141cf77f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/1200], Loss: 0.0746\n",
      "Epoch [1/5], Step [2/1200], Loss: 0.1215\n",
      "Epoch [2/5], Step [1/1200], Loss: 0.0581\n",
      "Epoch [2/5], Step [2/1200], Loss: 0.0184\n",
      "Epoch [3/5], Step [1/1200], Loss: 0.1512\n",
      "Epoch [3/5], Step [2/1200], Loss: 0.2745\n",
      "Epoch [4/5], Step [1/1200], Loss: 0.0497\n",
      "Epoch [4/5], Step [2/1200], Loss: 0.0699\n",
      "Epoch [5/5], Step [1/1200], Loss: 0.3059\n",
      "Epoch [5/5], Step [2/1200], Loss: 0.0232\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data loader\n",
    "\n",
    "# loade trainning MNIST set \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i > 1:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nOI-LHJgHVvw",
    "outputId": "7287f40c-f36b-45d0-b62d-828209ed0e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of 100 images trained model on the my dataset: 66.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on myDataSet\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in my_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of 100 images trained model on the my dataset: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IkM8HvalLrqI"
   },
   "source": [
    "## 1.2 experiment on 250 size trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "2gtvv5LnHc0I",
    "outputId": "7ae53c6a-0daf-4fe5-a268-797ddae0dfb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/1200], Loss: 0.0706\n",
      "Epoch [1/5], Step [2/1200], Loss: 0.1659\n",
      "Epoch [1/5], Step [3/1200], Loss: 0.0552\n",
      "Epoch [1/5], Step [4/1200], Loss: 0.2078\n",
      "Epoch [1/5], Step [5/1200], Loss: 0.0696\n",
      "Epoch [2/5], Step [1/1200], Loss: 0.0255\n",
      "Epoch [2/5], Step [2/1200], Loss: 0.0501\n",
      "Epoch [2/5], Step [3/1200], Loss: 0.1045\n",
      "Epoch [2/5], Step [4/1200], Loss: 0.0424\n",
      "Epoch [2/5], Step [5/1200], Loss: 0.0489\n",
      "Epoch [3/5], Step [1/1200], Loss: 0.1225\n",
      "Epoch [3/5], Step [2/1200], Loss: 0.0569\n",
      "Epoch [3/5], Step [3/1200], Loss: 0.1091\n",
      "Epoch [3/5], Step [4/1200], Loss: 0.1069\n",
      "Epoch [3/5], Step [5/1200], Loss: 0.0500\n",
      "Epoch [4/5], Step [1/1200], Loss: 0.0635\n",
      "Epoch [4/5], Step [2/1200], Loss: 0.1186\n",
      "Epoch [4/5], Step [3/1200], Loss: 0.0227\n",
      "Epoch [4/5], Step [4/1200], Loss: 0.2184\n",
      "Epoch [4/5], Step [5/1200], Loss: 0.1934\n",
      "Epoch [5/5], Step [1/1200], Loss: 0.0969\n",
      "Epoch [5/5], Step [2/1200], Loss: 0.1210\n",
      "Epoch [5/5], Step [3/1200], Loss: 0.0166\n",
      "Epoch [5/5], Step [4/1200], Loss: 0.0332\n",
      "Epoch [5/5], Step [5/1200], Loss: 0.1518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data loader\n",
    "\n",
    "# loade trainning MNIST set \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i > 4:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4BE2GZDZHyOY",
    "outputId": "744e2271-4267-44c2-9692-49bea2a08d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of 250 images trained model on the my dataset: 68.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on MNIST dataset\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in my_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of 250 images trained model on the my dataset: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Loj16xeRLw97"
   },
   "source": [
    "## 1.3 experiment on 500 size trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "U7YbkoLeIFq7",
    "outputId": "abda6d66-7da1-41a5-a299-c4731158a6cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/1200], Loss: 0.0568\n",
      "Epoch [1/5], Step [2/1200], Loss: 0.1204\n",
      "Epoch [1/5], Step [3/1200], Loss: 0.0863\n",
      "Epoch [1/5], Step [4/1200], Loss: 0.0193\n",
      "Epoch [1/5], Step [5/1200], Loss: 0.0751\n",
      "Epoch [1/5], Step [6/1200], Loss: 0.0257\n",
      "Epoch [1/5], Step [7/1200], Loss: 0.1827\n",
      "Epoch [1/5], Step [8/1200], Loss: 0.1464\n",
      "Epoch [1/5], Step [9/1200], Loss: 0.0615\n",
      "Epoch [1/5], Step [10/1200], Loss: 0.0615\n",
      "Epoch [2/5], Step [1/1200], Loss: 0.0896\n",
      "Epoch [2/5], Step [2/1200], Loss: 0.0287\n",
      "Epoch [2/5], Step [3/1200], Loss: 0.1033\n",
      "Epoch [2/5], Step [4/1200], Loss: 0.0350\n",
      "Epoch [2/5], Step [5/1200], Loss: 0.1826\n",
      "Epoch [2/5], Step [6/1200], Loss: 0.0317\n",
      "Epoch [2/5], Step [7/1200], Loss: 0.0823\n",
      "Epoch [2/5], Step [8/1200], Loss: 0.1101\n",
      "Epoch [2/5], Step [9/1200], Loss: 0.1387\n",
      "Epoch [2/5], Step [10/1200], Loss: 0.1394\n",
      "Epoch [3/5], Step [1/1200], Loss: 0.0379\n",
      "Epoch [3/5], Step [2/1200], Loss: 0.0287\n",
      "Epoch [3/5], Step [3/1200], Loss: 0.0618\n",
      "Epoch [3/5], Step [4/1200], Loss: 0.1528\n",
      "Epoch [3/5], Step [5/1200], Loss: 0.1078\n",
      "Epoch [3/5], Step [6/1200], Loss: 0.3177\n",
      "Epoch [3/5], Step [7/1200], Loss: 0.0551\n",
      "Epoch [3/5], Step [8/1200], Loss: 0.1169\n",
      "Epoch [3/5], Step [9/1200], Loss: 0.0379\n",
      "Epoch [3/5], Step [10/1200], Loss: 0.0129\n",
      "Epoch [4/5], Step [1/1200], Loss: 0.0753\n",
      "Epoch [4/5], Step [2/1200], Loss: 0.1044\n",
      "Epoch [4/5], Step [3/1200], Loss: 0.0712\n",
      "Epoch [4/5], Step [4/1200], Loss: 0.1321\n",
      "Epoch [4/5], Step [5/1200], Loss: 0.0460\n",
      "Epoch [4/5], Step [6/1200], Loss: 0.0998\n",
      "Epoch [4/5], Step [7/1200], Loss: 0.1236\n",
      "Epoch [4/5], Step [8/1200], Loss: 0.2159\n",
      "Epoch [4/5], Step [9/1200], Loss: 0.0520\n",
      "Epoch [4/5], Step [10/1200], Loss: 0.0442\n",
      "Epoch [5/5], Step [1/1200], Loss: 0.0647\n",
      "Epoch [5/5], Step [2/1200], Loss: 0.1449\n",
      "Epoch [5/5], Step [3/1200], Loss: 0.2781\n",
      "Epoch [5/5], Step [4/1200], Loss: 0.0883\n",
      "Epoch [5/5], Step [5/1200], Loss: 0.1453\n",
      "Epoch [5/5], Step [6/1200], Loss: 0.0329\n",
      "Epoch [5/5], Step [7/1200], Loss: 0.1503\n",
      "Epoch [5/5], Step [8/1200], Loss: 0.0326\n",
      "Epoch [5/5], Step [9/1200], Loss: 0.0184\n",
      "Epoch [5/5], Step [10/1200], Loss: 0.0529\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data loader\n",
    "\n",
    "# loade trainning MNIST set \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i > 9:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "40P8AqA6II0l",
    "outputId": "e89974d5-15d9-4df1-caac-dd194cdff32e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of 500 images trained model on the my dataset: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on myDataSet\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in my_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of 500 images trained model on the my dataset: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hqhqzm47JWfC"
   },
   "source": [
    "## 1.4 experiment on 1000 size trainning set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "id": "IGyV2JUOGHTG",
    "outputId": "6340b46c-f1cf-424d-8cde-35afef4d4157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [1/1200], Loss: 0.0120\n",
      "Epoch [1/5], Step [2/1200], Loss: 0.1557\n",
      "Epoch [1/5], Step [3/1200], Loss: 0.0498\n",
      "Epoch [1/5], Step [4/1200], Loss: 0.0168\n",
      "Epoch [1/5], Step [5/1200], Loss: 0.0265\n",
      "Epoch [1/5], Step [6/1200], Loss: 0.0753\n",
      "Epoch [1/5], Step [7/1200], Loss: 0.0644\n",
      "Epoch [1/5], Step [8/1200], Loss: 0.0198\n",
      "Epoch [1/5], Step [9/1200], Loss: 0.1191\n",
      "Epoch [1/5], Step [10/1200], Loss: 0.0466\n",
      "Epoch [1/5], Step [11/1200], Loss: 0.3127\n",
      "Epoch [1/5], Step [12/1200], Loss: 0.0728\n",
      "Epoch [1/5], Step [13/1200], Loss: 0.1182\n",
      "Epoch [1/5], Step [14/1200], Loss: 0.2562\n",
      "Epoch [1/5], Step [15/1200], Loss: 0.0844\n",
      "Epoch [1/5], Step [16/1200], Loss: 0.0859\n",
      "Epoch [1/5], Step [17/1200], Loss: 0.1902\n",
      "Epoch [1/5], Step [18/1200], Loss: 0.0768\n",
      "Epoch [1/5], Step [19/1200], Loss: 0.0727\n",
      "Epoch [1/5], Step [20/1200], Loss: 0.0614\n",
      "Epoch [2/5], Step [1/1200], Loss: 0.0515\n",
      "Epoch [2/5], Step [2/1200], Loss: 0.0375\n",
      "Epoch [2/5], Step [3/1200], Loss: 0.0705\n",
      "Epoch [2/5], Step [4/1200], Loss: 0.0562\n",
      "Epoch [2/5], Step [5/1200], Loss: 0.0729\n",
      "Epoch [2/5], Step [6/1200], Loss: 0.1545\n",
      "Epoch [2/5], Step [7/1200], Loss: 0.0767\n",
      "Epoch [2/5], Step [8/1200], Loss: 0.0307\n",
      "Epoch [2/5], Step [9/1200], Loss: 0.0711\n",
      "Epoch [2/5], Step [10/1200], Loss: 0.1464\n",
      "Epoch [2/5], Step [11/1200], Loss: 0.0440\n",
      "Epoch [2/5], Step [12/1200], Loss: 0.0433\n",
      "Epoch [2/5], Step [13/1200], Loss: 0.0755\n",
      "Epoch [2/5], Step [14/1200], Loss: 0.0639\n",
      "Epoch [2/5], Step [15/1200], Loss: 0.0332\n",
      "Epoch [2/5], Step [16/1200], Loss: 0.0135\n",
      "Epoch [2/5], Step [17/1200], Loss: 0.1410\n",
      "Epoch [2/5], Step [18/1200], Loss: 0.0319\n",
      "Epoch [2/5], Step [19/1200], Loss: 0.0082\n",
      "Epoch [2/5], Step [20/1200], Loss: 0.0108\n",
      "Epoch [3/5], Step [1/1200], Loss: 0.1283\n",
      "Epoch [3/5], Step [2/1200], Loss: 0.1578\n",
      "Epoch [3/5], Step [3/1200], Loss: 0.0229\n",
      "Epoch [3/5], Step [4/1200], Loss: 0.0231\n",
      "Epoch [3/5], Step [5/1200], Loss: 0.0510\n",
      "Epoch [3/5], Step [6/1200], Loss: 0.0162\n",
      "Epoch [3/5], Step [7/1200], Loss: 0.1096\n",
      "Epoch [3/5], Step [8/1200], Loss: 0.0789\n",
      "Epoch [3/5], Step [9/1200], Loss: 0.0525\n",
      "Epoch [3/5], Step [10/1200], Loss: 0.0163\n",
      "Epoch [3/5], Step [11/1200], Loss: 0.0128\n",
      "Epoch [3/5], Step [12/1200], Loss: 0.0892\n",
      "Epoch [3/5], Step [13/1200], Loss: 0.0739\n",
      "Epoch [3/5], Step [14/1200], Loss: 0.0578\n",
      "Epoch [3/5], Step [15/1200], Loss: 0.0601\n",
      "Epoch [3/5], Step [16/1200], Loss: 0.0671\n",
      "Epoch [3/5], Step [17/1200], Loss: 0.0828\n",
      "Epoch [3/5], Step [18/1200], Loss: 0.0077\n",
      "Epoch [3/5], Step [19/1200], Loss: 0.0269\n",
      "Epoch [3/5], Step [20/1200], Loss: 0.1492\n",
      "Epoch [4/5], Step [1/1200], Loss: 0.0319\n",
      "Epoch [4/5], Step [2/1200], Loss: 0.0223\n",
      "Epoch [4/5], Step [3/1200], Loss: 0.0588\n",
      "Epoch [4/5], Step [4/1200], Loss: 0.0755\n",
      "Epoch [4/5], Step [5/1200], Loss: 0.0371\n",
      "Epoch [4/5], Step [6/1200], Loss: 0.0809\n",
      "Epoch [4/5], Step [7/1200], Loss: 0.0213\n",
      "Epoch [4/5], Step [8/1200], Loss: 0.0880\n",
      "Epoch [4/5], Step [9/1200], Loss: 0.0954\n",
      "Epoch [4/5], Step [10/1200], Loss: 0.1407\n",
      "Epoch [4/5], Step [11/1200], Loss: 0.0300\n",
      "Epoch [4/5], Step [12/1200], Loss: 0.1095\n",
      "Epoch [4/5], Step [13/1200], Loss: 0.0202\n",
      "Epoch [4/5], Step [14/1200], Loss: 0.0151\n",
      "Epoch [4/5], Step [15/1200], Loss: 0.0352\n",
      "Epoch [4/5], Step [16/1200], Loss: 0.0646\n",
      "Epoch [4/5], Step [17/1200], Loss: 0.1348\n",
      "Epoch [4/5], Step [18/1200], Loss: 0.0856\n",
      "Epoch [4/5], Step [19/1200], Loss: 0.0057\n",
      "Epoch [4/5], Step [20/1200], Loss: 0.1028\n",
      "Epoch [5/5], Step [1/1200], Loss: 0.0106\n",
      "Epoch [5/5], Step [2/1200], Loss: 0.0162\n",
      "Epoch [5/5], Step [3/1200], Loss: 0.0203\n",
      "Epoch [5/5], Step [4/1200], Loss: 0.0509\n",
      "Epoch [5/5], Step [5/1200], Loss: 0.0216\n",
      "Epoch [5/5], Step [6/1200], Loss: 0.1055\n",
      "Epoch [5/5], Step [7/1200], Loss: 0.0246\n",
      "Epoch [5/5], Step [8/1200], Loss: 0.0530\n",
      "Epoch [5/5], Step [9/1200], Loss: 0.1653\n",
      "Epoch [5/5], Step [10/1200], Loss: 0.3039\n",
      "Epoch [5/5], Step [11/1200], Loss: 0.0216\n",
      "Epoch [5/5], Step [12/1200], Loss: 0.0419\n",
      "Epoch [5/5], Step [13/1200], Loss: 0.0314\n",
      "Epoch [5/5], Step [14/1200], Loss: 0.0686\n",
      "Epoch [5/5], Step [15/1200], Loss: 0.0600\n",
      "Epoch [5/5], Step [16/1200], Loss: 0.2127\n",
      "Epoch [5/5], Step [17/1200], Loss: 0.0256\n",
      "Epoch [5/5], Step [18/1200], Loss: 0.0451\n",
      "Epoch [5/5], Step [19/1200], Loss: 0.1293\n",
      "Epoch [5/5], Step [20/1200], Loss: 0.0513\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data loader\n",
    "\n",
    "# loade trainning MNIST set \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if i > 19:\n",
    "            break\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 1 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6y_HLukxGLNI",
    "outputId": "34d0c566-89ca-464a-99a4-033ad66ed429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of 50 images trained model on the my dataset: 68.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on myDataSet\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in my_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of 50 images trained model on the my dataset: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eY9UR5pCL22B"
   },
   "source": [
    "## 1.5 experiment on 60000 size trainning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "Y5dlq_ClINGp",
    "outputId": "1f3a5e7f-c22b-48a5-fe22-8c6f934d93ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2975\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1002\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1049\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0836\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1222\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0575\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0124\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0734\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0132\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0182\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0949\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1136\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0144\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0502\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0173\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0579\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0267\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0393\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0037\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0056\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0556\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0237\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0268\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0188\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0127\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0079\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0035\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0219\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0375\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0393\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Data loader\n",
    "\n",
    "# loade trainning MNIST set \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9CZSaUfQISue",
    "outputId": "38a7aa21-0da1-47aa-acb7-a35e3730934d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of 60000 images trained model on the my dataset: 73.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model on myDataSet\n",
    "\n",
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in my_test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Test Accuracy of 60000 images trained model on the my dataset: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EhN2wqUrL06W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wRZk9J60MI2U",
    "hqhqzm47JWfC",
    "IkM8HvalLrqI",
    "Loj16xeRLw97",
    "eY9UR5pCL22B"
   ],
   "name": "Part2 experiment with my dataset.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
